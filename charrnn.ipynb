{
 "metadata": {
  "name": "",
  "signature": "sha256:986b87d9603010e4eeb63e6fba6f85950d55edfc7e793407ce2d27743ead0792"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import cPickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's first define the model LSTM model we're going to use. Tensorflow offers two strong modules for this - rnn_cell and seq2seq"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from tensorflow.models.rnn import rnn_cell\n",
      "from tensorflow.models.rnn import seq2seq\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Model():\n",
      "    def _init_(self, args, infer=False):\n",
      "        self.args = args\n",
      "        if infer:\n",
      "            args.batch_size = 1\n",
      "            args.seq_length = 1\n",
      "            \n",
      "            if args.model == 'rnn':\n",
      "                cell_fn = rnn_cell.BasicRNNCell\n",
      "            elif args.model =='gru':\n",
      "                cell_fn = rnn_cell.GRUCell\n",
      "                \n",
      "            elif args.model == 'lstm':\n",
      "                cell_fn = rnn_cell.BasicLSTMCell\n",
      "            else:\n",
      "                raise Exception(\"model type not supported: {}\".format(args.model))\n",
      "            \n",
      "            cell = cell_fn(args.rnn_size)\n",
      "            \n",
      "            self.cell = cell = rnn_cell.MultiRNNCEll([cell]*args.num_layers)\n",
      "            self.input_data = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\n",
      "            self.targets = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\n",
      "            self.initial_state = cell.zero_state(args.batch_size, tf.float32)\n",
      "            \n",
      "            with tf.variable_scope('rnnlm'):\n",
      "                softmax_w = tf.get_variable(\"softmax_w\", [args.rnn_size, args.vocab_size])\n",
      "                softmax_b = tf.get_variable(\"softmax_b\", [args.vocab_size])\n",
      "                \n",
      "                embedding = tf.get_variable(\"embedding\", [args.vocab_size, args.rnn_size])\n",
      "                inputs = tf.split(1,args.seq_length, tf.nn.embedding_lookup(embedding, self.input_data))\n",
      "                inputs = [tf.squeeze(input_,[1]) for input_ in inputs]\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class TextLoader():\n",
      "    def _init_(self,data_dir, batch_size, seq_length):\n",
      "        self.data_dir = data_dir\n",
      "        self.batch_size = batch_size\n",
      "        self.seq_length  = seq_length\n",
      "        input_file = os.path.join(data_dir, \"input.txt\")\n",
      "        vocab_file = os.path.join(data_dir, \"vocab.pk1\")\n",
      "        tensor_file = os.path.join(data_dir, \"data.npy\")\n",
      "        \n",
      "        if not (os.path.exists(vocab) and os.path.exists(tensorfile) ):\n",
      "            self.preprocess(input_file, vocab_file,tensor_file)\n",
      "            \n",
      "        else:\n",
      "            self.load_preprocessed(vocab_file, tensor_file)\n",
      "            \n",
      "        self.create_batches()\n",
      "        self.reset_batch_pointer()\n",
      "        \n",
      "    def preprocess(self, input_file, vocab_file, tensor_file):\n",
      "        with open(input_file, \"r\", ) as f:\n",
      "            data = f.read()\n",
      "            counter = collections.Counter(data)\n",
      "            count_pairs = sorted(counter.items(), key = lambda x:-x[1])\n",
      "            self.chars, _ = list( zip(*count_pairs) )\n",
      "            self.vocab_size = len(self.chars)\n",
      "            self.vocab = dict(zip(self.chars, range(self.vocab_size)))\n",
      "            with open(vocab_file, 'w') as f:\n",
      "                cPickle.dump(self.chars,f)\n",
      "                \n",
      "            self.tensor = np.array(map(self.vocab.get,data))\n",
      "            np.save(tensor_file, self.tensor)\n",
      "    def load_preprocessed(self, vocab_file, tensor_file):\n",
      "        with open(vocab_file) as f:\n",
      "            self.chars = cPickle.load(f)\n",
      "        self.vocab_size = len(self.chars)\n",
      "        self.vocab = dict(zip(self.chars, range(self.vocab_size)))\n",
      "        self.tensor = np.load(tensor_file)\n",
      "        self.num_batches = self.tensor.size / (self.batch_size * self.seq_length)\n",
      "        \n",
      "        \n",
      "            \n",
      "    def create_batches(self):\n",
      "        self.num_batches = self.tensor.size/(self.batch_size * self.seq_length)\n",
      "        self.tensor = self.tensor[:self.num_batches*self.batch_size*self.seq_length]\n",
      "        xdata = self.tensor\n",
      "        ydata = np.copy(self.tensor)\n",
      "        ydata[:-1] = xdata[1:]\n",
      "        ydata[-1] = xdata[0]\n",
      "        self.x_batches = np.split(xdata.reshape(self.batch_size, -1 ),self.num_batches, 1)\n",
      "        self.y_batches = np.split(ydata.reshape(self.batch_size, -1 ),self.num_batches, 1)\n",
      "        \n",
      "    def next_batch(self):\n",
      "        x,y = self.x_batches[self.pointer], self.y_batches[self.pointer]\n",
      "        pointer+=1\n",
      "        return x,y\n",
      "    \n",
      "    def reset_batch_pointer(self):\n",
      "        self.pointer = 0\n",
      "            \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}